{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c646e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe74cf",
   "metadata": {},
   "source": [
    "### Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8635fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac20b725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d0a2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3236e-36,  0.0000e+00, -1.8554e+10,  4.5580e-41,  8.9683e-44])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2ae1dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcf00d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d5a6e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1367, 0.6263],\n",
      "        [0.9419, 0.3963]])\n",
      "tensor([[0.5600, 0.2104],\n",
      "        [0.7596, 0.1873]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eaa10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1913e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6967, 0.8367],\n",
      "        [1.7015, 0.5836]])\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd7b9a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6967, 0.8367],\n",
      "        [1.7015, 0.5836]])\n"
     ]
    }
   ],
   "source": [
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a9e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f928290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9187, 0.5063, 0.3060],\n",
       "        [0.6593, 0.5745, 0.0544],\n",
       "        [0.9191, 0.3275, 0.7650],\n",
       "        [0.6989, 0.1062, 0.4642],\n",
       "        [0.6631, 0.9661, 0.8487]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe7285ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a9ee75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9187, 0.5063, 0.3060, 0.6593, 0.5745],\n",
       "        [0.0544, 0.9191, 0.3275, 0.7650, 0.6989],\n",
       "        [0.1062, 0.4642, 0.6631, 0.9661, 0.8487]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1803a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f55a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49eae1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 5., 0.]])\n",
      "tensor([0., 5.])\n"
     ]
    }
   ],
   "source": [
    "b = a[:,1]\n",
    "a[1,1] = 5\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad922cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8013ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.from_numpy(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "231eecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e3f3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9494ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 6., 1.]])\n",
      "[[1. 1. 1.]\n",
      " [1. 6. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6ad167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3,3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d9f4eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0555, 0.9031, 0.9985],\n",
       "        [0.4294, 0.2303, 0.9579],\n",
       "        [0.9283, 0.2261, 0.1962]], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a96417",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31edd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3,3, requires_grad=True)\n",
    "b = a+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5226fdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2467, 2.6212, 2.4623],\n",
       "        [2.2402, 2.0733, 2.6827],\n",
       "        [2.3128, 2.8487, 2.6458]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91ebf66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.5413, 12.1132, 10.9873],\n",
      "        [ 9.4986,  8.4455, 12.5621],\n",
      "        [ 9.9744, 13.8129, 12.2920]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = b*(b+2)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbe999b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4593, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "281f75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2467, 0.6212, 0.4623],\n",
      "        [0.2402, 0.0733, 0.6827],\n",
      "        [0.3128, 0.8487, 0.6458]], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0e57462",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "376b1f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.4935, 7.2424, 6.9245],\n",
      "        [6.4803, 6.1467, 7.3654],\n",
      "        [6.6255, 7.6975, 7.2916]])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecebffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "b.sum().backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f8c07b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3553, 0.4161, 0.6694],\n",
       "        [0.5706, 0.2688, 0.2390],\n",
       "        [0.5648, 0.1770, 0.6837]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad_(False)\n",
    "#b.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bffa636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,2, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    b = a+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "749ffd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5026, 0.8944],\n",
      "        [0.5273, 0.5790]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cff7f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(2,2,requires_grad=True)\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f19dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(2,2,requires_grad=True)\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604e28b",
   "metadata": {},
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e61902",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fd10f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "#forward pass\n",
    "y1 = w*x\n",
    "loss = (y1-y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa21279b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5786e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83403930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73d4b1",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91417a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15064b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3,4], dtype=np.float32)\n",
    "Y = np.array([2,4,6,8], dtype=np.float32)\n",
    "w = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e9e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred  before training 0.0\n",
      "epoch 1 w =  1.200 loss = 30.00000000\n",
      "epoch 2 w =  1.680 loss = 4.79999924\n",
      "epoch 3 w =  1.872 loss = 0.76800019\n",
      "epoch 4 w =  1.949 loss = 0.12288000\n",
      "epoch 5 w =  1.980 loss = 0.01966083\n",
      "epoch 6 w =  1.992 loss = 0.00314574\n",
      "epoch 7 w =  1.997 loss = 0.00050331\n",
      "epoch 8 w =  1.999 loss = 0.00008053\n",
      "epoch 9 w =  1.999 loss = 0.00001288\n",
      "epoch 10 w =  2.000 loss = 0.00000206\n"
     ]
    }
   ],
   "source": [
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y, y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "\n",
    "def gradient(x, y,y_pred):\n",
    "    return np.dot(2*x,y_pred-y).mean()\n",
    "\n",
    "print(f'pred  before training {forward(5)}')\n",
    "\n",
    "n_iter = 10\n",
    "lr     = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = forward(X)\n",
    "    l   = loss(Y, y_pred)\n",
    "    dw     = gradient(X, Y, y_pred)\n",
    "    w     -= lr*dw\n",
    "    print(f'epoch {epoch+1} w =  {w:.3f} loss = {l:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7d912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 9.998951268196105\n"
     ]
    }
   ],
   "source": [
    "print(f'prediction {forward(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90aa3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04aa612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred  before training 0.0\n",
      "epoch 1 w =  0.300 loss = 30.00000000\n",
      "epoch 2 w =  0.555 loss = 21.67499924\n",
      "epoch 3 w =  0.772 loss = 15.66018772\n",
      "epoch 4 w =  0.956 loss = 11.31448650\n",
      "epoch 5 w =  1.113 loss = 8.17471695\n",
      "epoch 6 w =  1.246 loss = 5.90623236\n",
      "epoch 7 w =  1.359 loss = 4.26725292\n",
      "epoch 8 w =  1.455 loss = 3.08308983\n",
      "epoch 9 w =  1.537 loss = 2.22753215\n",
      "epoch 10 w =  1.606 loss = 1.60939169\n",
      "epoch 11 w =  1.665 loss = 1.16278565\n",
      "epoch 12 w =  1.716 loss = 0.84011245\n",
      "epoch 13 w =  1.758 loss = 0.60698116\n",
      "epoch 14 w =  1.794 loss = 0.43854395\n",
      "epoch 15 w =  1.825 loss = 0.31684780\n",
      "epoch 16 w =  1.851 loss = 0.22892261\n",
      "epoch 17 w =  1.874 loss = 0.16539653\n",
      "epoch 18 w =  1.893 loss = 0.11949898\n",
      "epoch 19 w =  1.909 loss = 0.08633806\n",
      "epoch 20 w =  1.922 loss = 0.06237914\n",
      "epoch 21 w =  1.934 loss = 0.04506890\n",
      "epoch 22 w =  1.944 loss = 0.03256231\n",
      "epoch 23 w =  1.952 loss = 0.02352631\n",
      "epoch 24 w =  1.960 loss = 0.01699772\n",
      "epoch 25 w =  1.966 loss = 0.01228084\n",
      "epoch 26 w =  1.971 loss = 0.00887291\n",
      "epoch 27 w =  1.975 loss = 0.00641066\n",
      "epoch 28 w =  1.979 loss = 0.00463169\n",
      "epoch 29 w =  1.982 loss = 0.00334642\n",
      "epoch 30 w =  1.985 loss = 0.00241778\n",
      "epoch 31 w =  1.987 loss = 0.00174685\n",
      "epoch 32 w =  1.989 loss = 0.00126211\n",
      "epoch 33 w =  1.991 loss = 0.00091188\n",
      "epoch 34 w =  1.992 loss = 0.00065882\n",
      "epoch 35 w =  1.993 loss = 0.00047601\n",
      "epoch 36 w =  1.994 loss = 0.00034392\n",
      "epoch 37 w =  1.995 loss = 0.00024848\n",
      "epoch 38 w =  1.996 loss = 0.00017952\n",
      "epoch 39 w =  1.996 loss = 0.00012971\n",
      "epoch 40 w =  1.997 loss = 0.00009371\n",
      "epoch 41 w =  1.997 loss = 0.00006770\n",
      "epoch 42 w =  1.998 loss = 0.00004891\n",
      "epoch 43 w =  1.998 loss = 0.00003534\n",
      "epoch 44 w =  1.998 loss = 0.00002553\n",
      "epoch 45 w =  1.999 loss = 0.00001845\n",
      "epoch 46 w =  1.999 loss = 0.00001333\n",
      "epoch 47 w =  1.999 loss = 0.00000963\n",
      "epoch 48 w =  1.999 loss = 0.00000696\n",
      "epoch 49 w =  1.999 loss = 0.00000503\n",
      "epoch 50 w =  1.999 loss = 0.00000363\n",
      "epoch 51 w =  1.999 loss = 0.00000262\n",
      "epoch 52 w =  2.000 loss = 0.00000190\n",
      "epoch 53 w =  2.000 loss = 0.00000137\n",
      "epoch 54 w =  2.000 loss = 0.00000099\n",
      "epoch 55 w =  2.000 loss = 0.00000071\n",
      "epoch 56 w =  2.000 loss = 0.00000052\n",
      "epoch 57 w =  2.000 loss = 0.00000037\n",
      "epoch 58 w =  2.000 loss = 0.00000027\n",
      "epoch 59 w =  2.000 loss = 0.00000019\n",
      "epoch 60 w =  2.000 loss = 0.00000014\n",
      "epoch 61 w =  2.000 loss = 0.00000010\n",
      "epoch 62 w =  2.000 loss = 0.00000007\n",
      "epoch 63 w =  2.000 loss = 0.00000005\n",
      "epoch 64 w =  2.000 loss = 0.00000004\n",
      "epoch 65 w =  2.000 loss = 0.00000003\n",
      "epoch 66 w =  2.000 loss = 0.00000002\n",
      "epoch 67 w =  2.000 loss = 0.00000001\n",
      "epoch 68 w =  2.000 loss = 0.00000001\n",
      "epoch 69 w =  2.000 loss = 0.00000001\n",
      "epoch 70 w =  2.000 loss = 0.00000001\n",
      "epoch 71 w =  2.000 loss = 0.00000000\n",
      "epoch 72 w =  2.000 loss = 0.00000000\n",
      "epoch 73 w =  2.000 loss = 0.00000000\n",
      "epoch 74 w =  2.000 loss = 0.00000000\n",
      "epoch 75 w =  2.000 loss = 0.00000000\n",
      "epoch 76 w =  2.000 loss = 0.00000000\n",
      "epoch 77 w =  2.000 loss = 0.00000000\n",
      "epoch 78 w =  2.000 loss = 0.00000000\n",
      "epoch 79 w =  2.000 loss = 0.00000000\n",
      "epoch 80 w =  2.000 loss = 0.00000000\n",
      "epoch 81 w =  2.000 loss = 0.00000000\n",
      "epoch 82 w =  2.000 loss = 0.00000000\n",
      "epoch 83 w =  2.000 loss = 0.00000000\n",
      "epoch 84 w =  2.000 loss = 0.00000000\n",
      "epoch 85 w =  2.000 loss = 0.00000000\n",
      "epoch 86 w =  2.000 loss = 0.00000000\n",
      "epoch 87 w =  2.000 loss = 0.00000000\n",
      "epoch 88 w =  2.000 loss = 0.00000000\n",
      "epoch 89 w =  2.000 loss = 0.00000000\n",
      "epoch 90 w =  2.000 loss = 0.00000000\n",
      "epoch 91 w =  2.000 loss = 0.00000000\n",
      "epoch 92 w =  2.000 loss = 0.00000000\n",
      "epoch 93 w =  2.000 loss = 0.00000000\n",
      "epoch 94 w =  2.000 loss = 0.00000000\n",
      "epoch 95 w =  2.000 loss = 0.00000000\n",
      "epoch 96 w =  2.000 loss = 0.00000000\n",
      "epoch 97 w =  2.000 loss = 0.00000000\n",
      "epoch 98 w =  2.000 loss = 0.00000000\n",
      "epoch 99 w =  2.000 loss = 0.00000000\n",
      "epoch 100 w =  2.000 loss = 0.00000000\n",
      "prediction 9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y, y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "\n",
    "\n",
    "print(f'pred  before training {forward(5)}')\n",
    "\n",
    "n_iter = 100\n",
    "lr     = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = forward(X)\n",
    "    l   = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    #dw     = gradient(X, Y, y_pred)\n",
    "    with torch.no_grad():\n",
    "        w     -= lr*w.grad\n",
    "    w.grad.zero_()\n",
    "    print(f'epoch {epoch+1} w =  {w:.3f} loss = {l:.8f}')\n",
    "print(f'prediction {forward(5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91df63e",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6e230f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred  before training 0.0\n",
      "epoch 1 w =  0.300 loss = 30.00000000\n",
      "epoch 2 w =  0.555 loss = 21.67499924\n",
      "epoch 3 w =  0.772 loss = 15.66018772\n",
      "epoch 4 w =  0.956 loss = 11.31448650\n",
      "epoch 5 w =  1.113 loss = 8.17471695\n",
      "epoch 6 w =  1.246 loss = 5.90623236\n",
      "epoch 7 w =  1.359 loss = 4.26725292\n",
      "epoch 8 w =  1.455 loss = 3.08308983\n",
      "epoch 9 w =  1.537 loss = 2.22753215\n",
      "epoch 10 w =  1.606 loss = 1.60939169\n",
      "epoch 11 w =  1.665 loss = 1.16278565\n",
      "epoch 12 w =  1.716 loss = 0.84011245\n",
      "epoch 13 w =  1.758 loss = 0.60698116\n",
      "epoch 14 w =  1.794 loss = 0.43854395\n",
      "epoch 15 w =  1.825 loss = 0.31684780\n",
      "epoch 16 w =  1.851 loss = 0.22892261\n",
      "epoch 17 w =  1.874 loss = 0.16539653\n",
      "epoch 18 w =  1.893 loss = 0.11949898\n",
      "epoch 19 w =  1.909 loss = 0.08633806\n",
      "epoch 20 w =  1.922 loss = 0.06237914\n",
      "epoch 21 w =  1.934 loss = 0.04506890\n",
      "epoch 22 w =  1.944 loss = 0.03256231\n",
      "epoch 23 w =  1.952 loss = 0.02352631\n",
      "epoch 24 w =  1.960 loss = 0.01699772\n",
      "epoch 25 w =  1.966 loss = 0.01228084\n",
      "epoch 26 w =  1.971 loss = 0.00887291\n",
      "epoch 27 w =  1.975 loss = 0.00641066\n",
      "epoch 28 w =  1.979 loss = 0.00463169\n",
      "epoch 29 w =  1.982 loss = 0.00334642\n",
      "epoch 30 w =  1.985 loss = 0.00241778\n",
      "epoch 31 w =  1.987 loss = 0.00174685\n",
      "epoch 32 w =  1.989 loss = 0.00126211\n",
      "epoch 33 w =  1.991 loss = 0.00091188\n",
      "epoch 34 w =  1.992 loss = 0.00065882\n",
      "epoch 35 w =  1.993 loss = 0.00047601\n",
      "epoch 36 w =  1.994 loss = 0.00034392\n",
      "epoch 37 w =  1.995 loss = 0.00024848\n",
      "epoch 38 w =  1.996 loss = 0.00017952\n",
      "epoch 39 w =  1.996 loss = 0.00012971\n",
      "epoch 40 w =  1.997 loss = 0.00009371\n",
      "epoch 41 w =  1.997 loss = 0.00006770\n",
      "epoch 42 w =  1.998 loss = 0.00004891\n",
      "epoch 43 w =  1.998 loss = 0.00003534\n",
      "epoch 44 w =  1.998 loss = 0.00002553\n",
      "epoch 45 w =  1.999 loss = 0.00001845\n",
      "epoch 46 w =  1.999 loss = 0.00001333\n",
      "epoch 47 w =  1.999 loss = 0.00000963\n",
      "epoch 48 w =  1.999 loss = 0.00000696\n",
      "epoch 49 w =  1.999 loss = 0.00000503\n",
      "epoch 50 w =  1.999 loss = 0.00000363\n",
      "epoch 51 w =  1.999 loss = 0.00000262\n",
      "epoch 52 w =  2.000 loss = 0.00000190\n",
      "epoch 53 w =  2.000 loss = 0.00000137\n",
      "epoch 54 w =  2.000 loss = 0.00000099\n",
      "epoch 55 w =  2.000 loss = 0.00000071\n",
      "epoch 56 w =  2.000 loss = 0.00000052\n",
      "epoch 57 w =  2.000 loss = 0.00000037\n",
      "epoch 58 w =  2.000 loss = 0.00000027\n",
      "epoch 59 w =  2.000 loss = 0.00000019\n",
      "epoch 60 w =  2.000 loss = 0.00000014\n",
      "epoch 61 w =  2.000 loss = 0.00000010\n",
      "epoch 62 w =  2.000 loss = 0.00000007\n",
      "epoch 63 w =  2.000 loss = 0.00000005\n",
      "epoch 64 w =  2.000 loss = 0.00000004\n",
      "epoch 65 w =  2.000 loss = 0.00000003\n",
      "epoch 66 w =  2.000 loss = 0.00000002\n",
      "epoch 67 w =  2.000 loss = 0.00000001\n",
      "epoch 68 w =  2.000 loss = 0.00000001\n",
      "epoch 69 w =  2.000 loss = 0.00000001\n",
      "epoch 70 w =  2.000 loss = 0.00000001\n",
      "epoch 71 w =  2.000 loss = 0.00000000\n",
      "epoch 72 w =  2.000 loss = 0.00000000\n",
      "epoch 73 w =  2.000 loss = 0.00000000\n",
      "epoch 74 w =  2.000 loss = 0.00000000\n",
      "epoch 75 w =  2.000 loss = 0.00000000\n",
      "epoch 76 w =  2.000 loss = 0.00000000\n",
      "epoch 77 w =  2.000 loss = 0.00000000\n",
      "epoch 78 w =  2.000 loss = 0.00000000\n",
      "epoch 79 w =  2.000 loss = 0.00000000\n",
      "epoch 80 w =  2.000 loss = 0.00000000\n",
      "epoch 81 w =  2.000 loss = 0.00000000\n",
      "epoch 82 w =  2.000 loss = 0.00000000\n",
      "epoch 83 w =  2.000 loss = 0.00000000\n",
      "epoch 84 w =  2.000 loss = 0.00000000\n",
      "epoch 85 w =  2.000 loss = 0.00000000\n",
      "epoch 86 w =  2.000 loss = 0.00000000\n",
      "epoch 87 w =  2.000 loss = 0.00000000\n",
      "epoch 88 w =  2.000 loss = 0.00000000\n",
      "epoch 89 w =  2.000 loss = 0.00000000\n",
      "epoch 90 w =  2.000 loss = 0.00000000\n",
      "epoch 91 w =  2.000 loss = 0.00000000\n",
      "epoch 92 w =  2.000 loss = 0.00000000\n",
      "epoch 93 w =  2.000 loss = 0.00000000\n",
      "epoch 94 w =  2.000 loss = 0.00000000\n",
      "epoch 95 w =  2.000 loss = 0.00000000\n",
      "epoch 96 w =  2.000 loss = 0.00000000\n",
      "epoch 97 w =  2.000 loss = 0.00000000\n",
      "epoch 98 w =  2.000 loss = 0.00000000\n",
      "epoch 99 w =  2.000 loss = 0.00000000\n",
      "epoch 100 w =  2.000 loss = 0.00000000\n",
      "prediction 9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "\n",
    "\n",
    "print(f'pred  before training {forward(5)}')\n",
    "\n",
    "loss      = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=lr) \n",
    "\n",
    "n_iter = 100\n",
    "lr     = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = forward(X)\n",
    "    l   = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f'epoch {epoch+1} w =  {w:.3f} loss = {l:.8f}')\n",
    "print(f'prediction {forward(5)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "700cdd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "pred  before training 0.07626056671142578\n",
      "epoch 1 w =  0.184  loss = 27.32563019\n",
      "epoch 2 w =  0.423  loss = 19.02868843\n",
      "epoch 3 w =  0.622  loss = 13.27121162\n",
      "epoch 4 w =  0.787  loss = 9.27581596\n",
      "epoch 5 w =  0.926  loss = 6.50309324\n",
      "epoch 6 w =  1.041  loss = 4.57876015\n",
      "epoch 7 w =  1.137  loss = 3.24310994\n",
      "epoch 8 w =  1.218  loss = 2.31593561\n",
      "epoch 9 w =  1.285  loss = 1.67219639\n",
      "epoch 10 w =  1.341  loss = 1.22512913\n",
      "epoch 11 w =  1.388  loss = 0.91453147\n",
      "epoch 12 w =  1.427  loss = 0.69862944\n",
      "epoch 13 w =  1.460  loss = 0.54843611\n",
      "epoch 14 w =  1.488  loss = 0.44383949\n",
      "epoch 15 w =  1.511  loss = 0.37088379\n",
      "epoch 16 w =  1.531  loss = 0.31988528\n",
      "epoch 17 w =  1.547  loss = 0.28412426\n",
      "epoch 18 w =  1.561  loss = 0.25893918\n",
      "epoch 19 w =  1.573  loss = 0.24109422\n",
      "epoch 20 w =  1.583  loss = 0.22834471\n",
      "epoch 21 w =  1.591  loss = 0.21913297\n",
      "epoch 22 w =  1.598  loss = 0.21237820\n",
      "epoch 23 w =  1.605  loss = 0.20733073\n",
      "epoch 24 w =  1.610  loss = 0.20346981\n",
      "epoch 25 w =  1.615  loss = 0.20043452\n",
      "epoch 26 w =  1.619  loss = 0.19797410\n",
      "epoch 27 w =  1.622  loss = 0.19591466\n",
      "epoch 28 w =  1.625  loss = 0.19413573\n",
      "epoch 29 w =  1.628  loss = 0.19255331\n",
      "epoch 30 w =  1.631  loss = 0.19110942\n",
      "epoch 31 w =  1.633  loss = 0.18976381\n",
      "epoch 32 w =  1.635  loss = 0.18848844\n",
      "epoch 33 w =  1.637  loss = 0.18726370\n",
      "epoch 34 w =  1.639  loss = 0.18607630\n",
      "epoch 35 w =  1.640  loss = 0.18491670\n",
      "epoch 36 w =  1.642  loss = 0.18377857\n",
      "epoch 37 w =  1.643  loss = 0.18265708\n",
      "epoch 38 w =  1.645  loss = 0.18154924\n",
      "epoch 39 w =  1.646  loss = 0.18045294\n",
      "epoch 40 w =  1.647  loss = 0.17936647\n",
      "epoch 41 w =  1.649  loss = 0.17828883\n",
      "epoch 42 w =  1.650  loss = 0.17721915\n",
      "epoch 43 w =  1.651  loss = 0.17615709\n",
      "epoch 44 w =  1.652  loss = 0.17510214\n",
      "epoch 45 w =  1.653  loss = 0.17405398\n",
      "epoch 46 w =  1.654  loss = 0.17301245\n",
      "epoch 47 w =  1.656  loss = 0.17197743\n",
      "epoch 48 w =  1.657  loss = 0.17094888\n",
      "epoch 49 w =  1.658  loss = 0.16992646\n",
      "epoch 50 w =  1.659  loss = 0.16891035\n",
      "epoch 51 w =  1.660  loss = 0.16790035\n",
      "epoch 52 w =  1.661  loss = 0.16689631\n",
      "epoch 53 w =  1.662  loss = 0.16589843\n",
      "epoch 54 w =  1.663  loss = 0.16490659\n",
      "epoch 55 w =  1.664  loss = 0.16392057\n",
      "epoch 56 w =  1.665  loss = 0.16294046\n",
      "epoch 57 w =  1.666  loss = 0.16196629\n",
      "epoch 58 w =  1.667  loss = 0.16099790\n",
      "epoch 59 w =  1.668  loss = 0.16003530\n",
      "epoch 60 w =  1.669  loss = 0.15907846\n",
      "epoch 61 w =  1.670  loss = 0.15812746\n",
      "epoch 62 w =  1.671  loss = 0.15718193\n",
      "epoch 63 w =  1.672  loss = 0.15624219\n",
      "epoch 64 w =  1.673  loss = 0.15530802\n",
      "epoch 65 w =  1.674  loss = 0.15437949\n",
      "epoch 66 w =  1.675  loss = 0.15345651\n",
      "epoch 67 w =  1.676  loss = 0.15253894\n",
      "epoch 68 w =  1.677  loss = 0.15162699\n",
      "epoch 69 w =  1.678  loss = 0.15072043\n",
      "epoch 70 w =  1.679  loss = 0.14981934\n",
      "epoch 71 w =  1.680  loss = 0.14892353\n",
      "epoch 72 w =  1.681  loss = 0.14803319\n",
      "epoch 73 w =  1.682  loss = 0.14714807\n",
      "epoch 74 w =  1.683  loss = 0.14626829\n",
      "epoch 75 w =  1.684  loss = 0.14539379\n",
      "epoch 76 w =  1.685  loss = 0.14452457\n",
      "epoch 77 w =  1.685  loss = 0.14366038\n",
      "epoch 78 w =  1.686  loss = 0.14280148\n",
      "epoch 79 w =  1.687  loss = 0.14194772\n",
      "epoch 80 w =  1.688  loss = 0.14109905\n",
      "epoch 81 w =  1.689  loss = 0.14025536\n",
      "epoch 82 w =  1.690  loss = 0.13941683\n",
      "epoch 83 w =  1.691  loss = 0.13858329\n",
      "epoch 84 w =  1.692  loss = 0.13775475\n",
      "epoch 85 w =  1.693  loss = 0.13693118\n",
      "epoch 86 w =  1.694  loss = 0.13611242\n",
      "epoch 87 w =  1.695  loss = 0.13529858\n",
      "epoch 88 w =  1.696  loss = 0.13448969\n",
      "epoch 89 w =  1.697  loss = 0.13368563\n",
      "epoch 90 w =  1.698  loss = 0.13288632\n",
      "epoch 91 w =  1.698  loss = 0.13209182\n",
      "epoch 92 w =  1.699  loss = 0.13130201\n",
      "epoch 93 w =  1.700  loss = 0.13051693\n",
      "epoch 94 w =  1.701  loss = 0.12973666\n",
      "epoch 95 w =  1.702  loss = 0.12896103\n",
      "epoch 96 w =  1.703  loss = 0.12818995\n",
      "epoch 97 w =  1.704  loss = 0.12742355\n",
      "epoch 98 w =  1.705  loss = 0.12666169\n",
      "epoch 99 w =  1.706  loss = 0.12590444\n",
      "epoch 100 w =  1.706  loss = 0.12515159\n",
      "prediction 9.395330429077148\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "#w = torch.tensor(0.0, dtype = torch.float32, requires_grad=True)\n",
    "\n",
    "print(n_samples, n_features)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "input_size  = n_features\n",
    "output_size = n_features  \n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "\n",
    "print(f'pred  before training {model(X_test).item()}')\n",
    "\n",
    "loss      = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) \n",
    "\n",
    "n_iter = 100\n",
    "lr     = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = model(X)\n",
    "    l   = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    [w,b] = model.parameters()\n",
    "    print(f'epoch {epoch+1} w =  {w[0][0].item():.3f}  loss = {l:.8f}')\n",
    "print(f'prediction {model(X_test).item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "633fa6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "pred  before training -0.11693739891052246\n",
      "epoch 1 w =  0.271  loss = 30.53306580\n",
      "epoch 2 w =  0.523  loss = 21.20793724\n",
      "epoch 3 w =  0.733  loss = 14.73729992\n",
      "epoch 4 w =  0.908  loss = 10.24733543\n",
      "epoch 5 w =  1.054  loss = 7.13171291\n",
      "epoch 6 w =  1.176  loss = 4.96972179\n",
      "epoch 7 w =  1.278  loss = 3.46943521\n",
      "epoch 8 w =  1.362  loss = 2.42829227\n",
      "epoch 9 w =  1.433  loss = 1.70573962\n",
      "epoch 10 w =  1.492  loss = 1.20425141\n",
      "epoch 11 w =  1.541  loss = 0.85615593\n",
      "epoch 12 w =  1.582  loss = 0.61449754\n",
      "epoch 13 w =  1.617  loss = 0.44669309\n",
      "epoch 14 w =  1.645  loss = 0.33013627\n",
      "epoch 15 w =  1.669  loss = 0.24913892\n",
      "epoch 16 w =  1.690  loss = 0.19281664\n",
      "epoch 17 w =  1.706  loss = 0.15361673\n",
      "epoch 18 w =  1.721  loss = 0.12629804\n",
      "epoch 19 w =  1.732  loss = 0.10722433\n",
      "epoch 20 w =  1.743  loss = 0.09387249\n",
      "epoch 21 w =  1.751  loss = 0.08449142\n",
      "epoch 22 w =  1.758  loss = 0.07786642\n",
      "epoch 23 w =  1.764  loss = 0.07315443\n",
      "epoch 24 w =  1.769  loss = 0.06977061\n",
      "epoch 25 w =  1.774  loss = 0.06730890\n",
      "epoch 26 w =  1.777  loss = 0.06548780\n",
      "epoch 27 w =  1.781  loss = 0.06411192\n",
      "epoch 28 w =  1.783  loss = 0.06304552\n",
      "epoch 29 w =  1.786  loss = 0.06219462\n",
      "epoch 30 w =  1.788  loss = 0.06149393\n",
      "epoch 31 w =  1.790  loss = 0.06089808\n",
      "epoch 32 w =  1.792  loss = 0.06037565\n",
      "epoch 33 w =  1.793  loss = 0.05990484\n",
      "epoch 34 w =  1.794  loss = 0.05947042\n",
      "epoch 35 w =  1.796  loss = 0.05906191\n",
      "epoch 36 w =  1.797  loss = 0.05867213\n",
      "epoch 37 w =  1.798  loss = 0.05829589\n",
      "epoch 38 w =  1.799  loss = 0.05792965\n",
      "epoch 39 w =  1.800  loss = 0.05757108\n",
      "epoch 40 w =  1.800  loss = 0.05721837\n",
      "epoch 41 w =  1.801  loss = 0.05687030\n",
      "epoch 42 w =  1.802  loss = 0.05652620\n",
      "epoch 43 w =  1.803  loss = 0.05618538\n",
      "epoch 44 w =  1.803  loss = 0.05584749\n",
      "epoch 45 w =  1.804  loss = 0.05551219\n",
      "epoch 46 w =  1.805  loss = 0.05517937\n",
      "epoch 47 w =  1.805  loss = 0.05484886\n",
      "epoch 48 w =  1.806  loss = 0.05452041\n",
      "epoch 49 w =  1.807  loss = 0.05419414\n",
      "epoch 50 w =  1.807  loss = 0.05386992\n",
      "epoch 51 w =  1.808  loss = 0.05354769\n",
      "epoch 52 w =  1.808  loss = 0.05322738\n",
      "epoch 53 w =  1.809  loss = 0.05290909\n",
      "epoch 54 w =  1.810  loss = 0.05259269\n",
      "epoch 55 w =  1.810  loss = 0.05227825\n",
      "epoch 56 w =  1.811  loss = 0.05196564\n",
      "epoch 57 w =  1.811  loss = 0.05165492\n",
      "epoch 58 w =  1.812  loss = 0.05134604\n",
      "epoch 59 w =  1.813  loss = 0.05103907\n",
      "epoch 60 w =  1.813  loss = 0.05073392\n",
      "epoch 61 w =  1.814  loss = 0.05043063\n",
      "epoch 62 w =  1.814  loss = 0.05012906\n",
      "epoch 63 w =  1.815  loss = 0.04982937\n",
      "epoch 64 w =  1.815  loss = 0.04953148\n",
      "epoch 65 w =  1.816  loss = 0.04923531\n",
      "epoch 66 w =  1.816  loss = 0.04894092\n",
      "epoch 67 w =  1.817  loss = 0.04864834\n",
      "epoch 68 w =  1.818  loss = 0.04835746\n",
      "epoch 69 w =  1.818  loss = 0.04806834\n",
      "epoch 70 w =  1.819  loss = 0.04778095\n",
      "epoch 71 w =  1.819  loss = 0.04749528\n",
      "epoch 72 w =  1.820  loss = 0.04721128\n",
      "epoch 73 w =  1.820  loss = 0.04692899\n",
      "epoch 74 w =  1.821  loss = 0.04664844\n",
      "epoch 75 w =  1.821  loss = 0.04636957\n",
      "epoch 76 w =  1.822  loss = 0.04609234\n",
      "epoch 77 w =  1.822  loss = 0.04581673\n",
      "epoch 78 w =  1.823  loss = 0.04554279\n",
      "epoch 79 w =  1.823  loss = 0.04527050\n",
      "epoch 80 w =  1.824  loss = 0.04499986\n",
      "epoch 81 w =  1.825  loss = 0.04473081\n",
      "epoch 82 w =  1.825  loss = 0.04446335\n",
      "epoch 83 w =  1.826  loss = 0.04419751\n",
      "epoch 84 w =  1.826  loss = 0.04393325\n",
      "epoch 85 w =  1.827  loss = 0.04367059\n",
      "epoch 86 w =  1.827  loss = 0.04340950\n",
      "epoch 87 w =  1.828  loss = 0.04314993\n",
      "epoch 88 w =  1.828  loss = 0.04289197\n",
      "epoch 89 w =  1.829  loss = 0.04263551\n",
      "epoch 90 w =  1.829  loss = 0.04238063\n",
      "epoch 91 w =  1.830  loss = 0.04212722\n",
      "epoch 92 w =  1.830  loss = 0.04187534\n",
      "epoch 93 w =  1.831  loss = 0.04162500\n",
      "epoch 94 w =  1.831  loss = 0.04137610\n",
      "epoch 95 w =  1.832  loss = 0.04112872\n",
      "epoch 96 w =  1.832  loss = 0.04088283\n",
      "epoch 97 w =  1.833  loss = 0.04063840\n",
      "epoch 98 w =  1.833  loss = 0.04039545\n",
      "epoch 99 w =  1.834  loss = 0.04015391\n",
      "epoch 100 w =  1.834  loss = 0.03991382\n",
      "prediction 9.658522605895996\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "#w = torch.tensor(0.0, dtype = torch.float32, requires_grad=True)\n",
    "\n",
    "print(n_samples, n_features)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "input_size  = n_features\n",
    "output_size = n_features  \n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "\n",
    "print(f'pred  before training {model(X_test).item()}')\n",
    "\n",
    "loss      = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) \n",
    "\n",
    "n_iter = 100\n",
    "lr     = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = model(X)\n",
    "    l   = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    [w,b] = model.parameters()\n",
    "    print(f'epoch {epoch+1} w =  {w[0][0].item():.3f}  loss = {l:.8f}')\n",
    "print(f'prediction {model(X_test).item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500fc1f",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a9dec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16fe4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c41cd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.view(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45cca33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7f2c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss: 4286.5962\n",
      "epoch:20, loss: 3202.4099\n",
      "epoch:30, loss: 2417.2410\n",
      "epoch:40, loss: 1848.0507\n",
      "epoch:50, loss: 1435.0472\n",
      "epoch:60, loss: 1135.1167\n",
      "epoch:70, loss: 917.1295\n",
      "epoch:80, loss: 758.5838\n",
      "epoch:90, loss: 643.1937\n",
      "epoch:100, loss: 559.1614\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_size  = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "num_epoch = 100\n",
    "for epoch in range(num_epoch):\n",
    "    y_pred = model(X)\n",
    "    loss   = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if((epoch+1)%10==0):\n",
    "        print(f'epoch:{epoch+1}, loss: {loss:.4f}')\n",
    "        \n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5155d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de4a2556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "bc  = datasets.load_breast_cancer()\n",
    "\n",
    "X,y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features            = X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.fit_transform(X_test)\n",
    "\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7f968a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.view(y_train.shape[0],1)\n",
    "y_test  = y_test.view(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e788c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss: 0.6005\n",
      "epoch:20, loss: 0.4922\n",
      "epoch:30, loss: 0.4222\n",
      "epoch:40, loss: 0.3736\n",
      "epoch:50, loss: 0.3379\n",
      "epoch:60, loss: 0.3105\n",
      "epoch:70, loss: 0.2888\n",
      "epoch:80, loss: 0.2710\n",
      "epoch:90, loss: 0.2563\n",
      "epoch:100, loss: 0.2437\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "model     = LogisticRegression(n_features)\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss   = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if((epoch+1)%10==0):\n",
    "        print(f'epoch:{epoch+1}, loss: {loss:.4f}')\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7caf7852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9298\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_predicted_cls = y_pred.round()\n",
    "    acc  = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
    "    print(f'accuracy {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670d182",
   "metadata": {},
   "source": [
    "### Pytorch dataset and data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc4dbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('wine.csv', delimiter = \",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:,1:])\n",
    "        self.y = torch.from_numpy(xy[:,[0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b71a0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76cf46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2835ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]), tensor([1.]))\n",
      "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]), tensor([1.]))\n",
      "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]), tensor([1.]))\n",
      "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "567c5d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3880e+01, 1.8900e+00, 2.5900e+00, 1.5000e+01, 1.0100e+02, 3.2500e+00,\n",
      "         3.5600e+00, 1.7000e-01, 1.7000e+00, 5.4300e+00, 8.8000e-01, 3.5600e+00,\n",
      "         1.0950e+03],\n",
      "        [1.2250e+01, 3.8800e+00, 2.2000e+00, 1.8500e+01, 1.1200e+02, 1.3800e+00,\n",
      "         7.8000e-01, 2.9000e-01, 1.1400e+00, 8.2100e+00, 6.5000e-01, 2.0000e+00,\n",
      "         8.5500e+02],\n",
      "        [1.2220e+01, 1.2900e+00, 1.9400e+00, 1.9000e+01, 9.2000e+01, 2.3600e+00,\n",
      "         2.0400e+00, 3.9000e-01, 2.0800e+00, 2.7000e+00, 8.6000e-01, 3.0200e+00,\n",
      "         3.1200e+02],\n",
      "        [1.3830e+01, 1.6500e+00, 2.6000e+00, 1.7200e+01, 9.4000e+01, 2.4500e+00,\n",
      "         2.9900e+00, 2.2000e-01, 2.2900e+00, 5.6000e+00, 1.2400e+00, 3.3700e+00,\n",
      "         1.2650e+03]]) tensor([[1.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "dataiter         = iter(dataloader)\n",
    "data             = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7421934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "\n",
    "print(total_samples, n_iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0abd960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 5/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45 inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45 inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45 inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45 inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        if((i+1)%5==0):\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations} inputs {inputs.shape}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0548f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329132fe40f344e9a6cb2ae4ad0510bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab60e5da7aaa48bfbe1d83460fb43e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbc1e7737014b8386c4bd3fa585d92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a3b13e1c1843e0b00fabf5d1641d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/ml/my_env/lib/python3.6/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root = \"./data\", transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd951a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('wine.csv', delimiter = \",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:,1:]\n",
    "        self.y = xy[:,[0]]\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        \n",
    "        if(self.transform):\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target\n",
    "    \n",
    "    \n",
    "    \n",
    "dataset = WineDataset(transform = None)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features)\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset  = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e92c3",
   "metadata": {},
   "source": [
    "### Softmax and Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e60b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis=0)\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "print(softmax(x))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01678bb9",
   "metadata": {},
   "source": [
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "print(torch.softmax(x , dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fd11bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 numpy 0.3567\n",
      "loss2 numpy 2.3026\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    return -np.sum(actual*np.log(predicted))\n",
    "\n",
    "Y = np.array([1,0,0])\n",
    "y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "y_pred_bad  = np.array([0.1, 0.3, 0.6])\n",
    "\n",
    "l1 = cross_entropy(Y, y_pred_good)\n",
    "l2 = cross_entropy(Y, y_pred_bad)\n",
    "\n",
    "print(f'loss1 numpy {l1:.4f}')\n",
    "print(f'loss2 numpy {l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df840a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4170299470424652\n",
      "1.840616226196289\n",
      "tensor([0]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "Y    = torch.tensor([0]) #class name\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) #no softmax\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])  #no softmax\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad,  Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item())\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print( predictions1, predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a6aa1",
   "metadata": {},
   "source": [
    "### Feedforward nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8d865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/ml/my_env/lib/python3.6/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs  = 2\n",
    "batch_size  = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform = transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2980d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 100/600, loss = 0.3994\n",
      "epoch 1/2, step 200/600, loss = 0.2980\n",
      "epoch 1/2, step 300/600, loss = 0.2957\n",
      "epoch 1/2, step 400/600, loss = 0.2550\n",
      "epoch 1/2, step 500/600, loss = 0.1520\n",
      "epoch 1/2, step 600/600, loss = 0.2070\n",
      "epoch 2/2, step 100/600, loss = 0.1090\n",
      "epoch 2/2, step 200/600, loss = 0.2143\n",
      "epoch 2/2, step 300/600, loss = 0.1928\n",
      "epoch 2/2, step 400/600, loss = 0.2059\n",
      "epoch 2/2, step 500/600, loss = 0.1619\n",
      "epoch 2/2, step 600/600, loss = 0.0602\n",
      "accuracy = 95.37\n"
     ]
    }
   ],
   "source": [
    "# for i in range(6):\n",
    "#     plt.subplot(2,3, i+1)\n",
    "#     plt.imshow(samples[i][0], cmap='gray')\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if((i+1)%100 == 0):\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples +=labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    acc = 100.0* n_correct /n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad57597",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1237bcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2000/12500], Loss: 2.2839\n",
      "Epoch [1/5], Step [4000/12500], Loss: 2.2773\n",
      "Epoch [1/5], Step [6000/12500], Loss: 2.2827\n",
      "Epoch [1/5], Step [8000/12500], Loss: 2.2593\n",
      "Epoch [1/5], Step [10000/12500], Loss: 2.0608\n",
      "Epoch [1/5], Step [12000/12500], Loss: 1.7202\n",
      "Epoch [2/5], Step [2000/12500], Loss: 2.5459\n",
      "Epoch [2/5], Step [4000/12500], Loss: 1.6835\n",
      "Epoch [2/5], Step [6000/12500], Loss: 1.5357\n",
      "Epoch [2/5], Step [8000/12500], Loss: 2.2192\n",
      "Epoch [2/5], Step [10000/12500], Loss: 1.9737\n",
      "Epoch [2/5], Step [12000/12500], Loss: 1.5188\n",
      "Epoch [3/5], Step [2000/12500], Loss: 1.8820\n",
      "Epoch [3/5], Step [4000/12500], Loss: 1.0353\n",
      "Epoch [3/5], Step [6000/12500], Loss: 1.9761\n",
      "Epoch [3/5], Step [8000/12500], Loss: 1.2276\n",
      "Epoch [3/5], Step [10000/12500], Loss: 1.2666\n",
      "Epoch [3/5], Step [12000/12500], Loss: 1.5842\n",
      "Epoch [4/5], Step [2000/12500], Loss: 1.2638\n",
      "Epoch [4/5], Step [4000/12500], Loss: 1.0517\n",
      "Epoch [4/5], Step [6000/12500], Loss: 1.4958\n",
      "Epoch [4/5], Step [8000/12500], Loss: 1.8580\n",
      "Epoch [4/5], Step [10000/12500], Loss: 1.4426\n",
      "Epoch [4/5], Step [12000/12500], Loss: 1.9334\n",
      "Epoch [5/5], Step [2000/12500], Loss: 1.3564\n",
      "Epoch [5/5], Step [4000/12500], Loss: 1.3364\n",
      "Epoch [5/5], Step [6000/12500], Loss: 1.2836\n",
      "Epoch [5/5], Step [8000/12500], Loss: 1.3799\n",
      "Epoch [5/5], Step [10000/12500], Loss: 2.2120\n",
      "Epoch [5/5], Step [12000/12500], Loss: 1.5445\n",
      "Finished Training\n",
      "Accuracy of the network: 49.48 %\n",
      "Accuracy of plane: 59.7 %\n",
      "Accuracy of car: 70.5 %\n",
      "Accuracy of bird: 29.0 %\n",
      "Accuracy of cat: 32.2 %\n",
      "Accuracy of deer: 36.7 %\n",
      "Accuracy of dog: 60.7 %\n",
      "Accuracy of frog: 61.5 %\n",
      "Accuracy of horse: 39.9 %\n",
      "Accuracy of ship: 55.8 %\n",
      "Accuracy of truck: 48.8 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81329afb",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "#### Finetuning the convnet ####\n",
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# Learning rate scheduling should be applied after optimizer’s update\n",
    "# e.g., you should write your code this way:\n",
    "# for epoch in range(100):\n",
    "#     train(...)\n",
    "#     validate(...)\n",
    "#     scheduler.step()\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
    "\n",
    "\n",
    "#### ConvNet as fixed feature extractor ####\n",
    "# Here, we need to freeze all the network except the final layer.\n",
    "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268ec3a",
   "metadata": {},
   "source": [
    "### Tensorboard Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "540553d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "epoch 1/2, step 100/600, loss = 0.3706\n",
      "epoch 1/2, step 200/600, loss = 0.4565\n",
      "epoch 1/2, step 300/600, loss = 0.3055\n",
      "epoch 1/2, step 400/600, loss = 0.3062\n",
      "epoch 1/2, step 500/600, loss = 0.2634\n",
      "epoch 1/2, step 600/600, loss = 0.3206\n",
      "epoch 2/2, step 100/600, loss = 0.2717\n",
      "epoch 2/2, step 200/600, loss = 0.2340\n",
      "epoch 2/2, step 300/600, loss = 0.1896\n",
      "epoch 2/2, step 400/600, loss = 0.1367\n",
      "epoch 2/2, step 500/600, loss = 0.2157\n",
      "epoch 2/2, step 600/600, loss = 0.2251\n",
      "accuracy = 95.48\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"runs/mnist\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs  = 2\n",
    "batch_size  = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform = transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image(\"mnist_images\", img_grid)\n",
    "writer.close()\n",
    "#sys.exit()\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "writer.add_graph(model, samples.reshape(-1,28*28))\n",
    "writer.close()\n",
    "#sys.exit()\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss     = loss.item()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        running_correct += (predictions == labels).sum().item() \n",
    "        \n",
    "        if((i+1)%100 == 0):\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "            writer.add_scalar('training_loss ',running_loss/100, epoch*n_total_steps+i)\n",
    "            writer.add_scalar('accuracy ',running_correct/100, epoch*n_total_steps+i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "\n",
    "            \n",
    "labels = []\n",
    "preds  = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels1 in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels1 = labels1.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples +=labels1.shape[0]\n",
    "        n_correct += (predictions == labels1).sum().item()\n",
    "        \n",
    "        class_predictions = [F.softmax(output, dim=0) for output in outputs]\n",
    "        \n",
    "        preds.append(class_predictions)\n",
    "        labels.append(predictions)\n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "    labels = torch.cat(labels)\n",
    "        \n",
    "    acc = 100.0* n_correct /n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    \n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = labels ==i\n",
    "        preds_i  = preds[:,i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6010d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaee128",
   "metadata": {},
   "source": [
    "### Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f0b2d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1805, -0.1222,  0.2921,  0.1810,  0.3617, -0.1081]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2314], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1805, -0.1222,  0.2921,  0.1810,  0.3617, -0.1081]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2314], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "FILE  = 'model.pth'\n",
    "torch.save(model.state_dict(), FILE)\n",
    "# model = torch.load(FILE)\n",
    "# model.eval()\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     print(param)\n",
    "\n",
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(FILE))\n",
    "loaded_model.eval()\n",
    "\n",
    "\n",
    "for param in loaded_model.parameters():\n",
    "    print(param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f338d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[ 0.2634,  0.0660,  0.0249, -0.3690,  0.3331,  0.1786]])), ('linear.bias', tensor([-0.0986]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63d842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
